{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PathPilot ML training\n",
    "##### Author: [Joseph Selva Raj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from micromlgen import port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "Load the LIDAR measurement data from txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4    5    6    7    8    9    ...  231  232  233  234  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   235  236  237  238  239  240  \n",
      "0    0    0    0    0    0    D  \n",
      "1    0    0    0    0    0    D  \n",
      "2    0    0    0    0    0    D  \n",
      "3    0    0    0    0    0    D  \n",
      "4    0    0    0    0    0    D  \n",
      "\n",
      "[5 rows x 241 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\josep\\\\Documents\\\\Github Repo\\\\PathPilot\\\\PathPilot\\\\DATA_RLCIRCLE.TXT', header=None)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "Rename the last column as \"label\" and clean the data by eliminating all data strings that are not annotated with \"Forward\" command labels.\n",
    "\n",
    "The processed data should only contain the LIDAR measurements and the corresponding command labels:\n",
    "- F - forward\n",
    "- R - forward right\n",
    "- L - forward left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts before cleaning the data: \n",
      " Label\n",
      "F    10409\n",
      "R     3570\n",
      "L     3494\n",
      "D      136\n",
      "s      122\n",
      "b       30\n",
      "r        1\n",
      "Name: count, dtype: int64\n",
      "Label counts after cleaning the data: \n",
      " Label\n",
      "F    10409\n",
      "R     3570\n",
      "L     3494\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data.rename(columns={data.columns[-1]: 'Label'}, inplace=True)\n",
    "print(f\"Label counts before cleaning the data: \\n {data['Label'].value_counts()}\")\n",
    "data = data[data['Label'].isin(['F', 'L', 'R'])]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(f\"Label counts after cleaning the data: \\n {data['Label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spilt data into train and test sets\n",
    "Separate X and Y as the input and output data and divide them into train and test sets with train_test_split. \n",
    "Label encoder is used to convert the labels from character to number format to interface with the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding mapping for motor control in Arduino code: {'F': 0, 'L': 1, 'R': 2}\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(f\"Label encoding mapping for motor control in Arduino code: {label_mapping}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data selection\n",
    "\n",
    "Data selection is performed after the splitting to train and test sets, otherwise it may be exposed to data leakage problem. Data selection is performed with SelectKBest from sklearn package. The number of selected features is defined as K. The selected features are the Lidar data measurement angles that are most important for the classification, and have to be used in the Arduino code for the real-time classification. Write about the accuracy with the plot of different vlaues of K, and the accuracy with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected features:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]\n"
     ]
    }
   ],
   "source": [
    "# Optimal k value found previously\n",
    "optimal_k = \n",
    "\n",
    "# Feature selection with the optimal k\n",
    "k_best = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "k_best.fit(X_train, y_train)\n",
    "\n",
    "selected_feature_indices = k_best.get_support(indices=True)\n",
    "print(\"selected features: \", list(X.columns[selected_feature_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "Training the model is a straightforward process, thanks to all the libraries available in Python. The outcome of the training process depends on the dataset and the preceding steps. Post-training, accuracy will be computed using the test set, and a higher accuracy is desirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.26%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           F       0.85      0.89      0.87      2068\n",
      "           L       0.85      0.77      0.81       684\n",
      "           R       0.82      0.77      0.79       743\n",
      "\n",
      "    accuracy                           0.84      3495\n",
      "   macro avg       0.84      0.81      0.82      3495\n",
      "weighted avg       0.84      0.84      0.84      3495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=4,random_state=42)\n",
    "clf.fit(X_train.iloc[:, selected_feature_indices], y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test.iloc[:, selected_feature_indices])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_test, y_pred, target_names=class_names, zero_division=0)\n",
    "print('Classification Report:\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the Classifier\n",
    "\n",
    "Export the trained classifier to a C code header file via the micromlgen library, so that it can be used in the Arduino code for real-time classification.\n",
    "Write about the relationship between the sketch size & the accuracy. IDE will show the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_file = open(\"xgboost.json\", mode=\"w+\")\n",
    "tmp_file.close()\n",
    "arduino_code = open(\"XGBoost.h\", mode=\"w+\")\n",
    "arduino_code.write(port(clf, classname='XGBClassifier', tmp_file='xgboost.json'))\n",
    "arduino_code.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
